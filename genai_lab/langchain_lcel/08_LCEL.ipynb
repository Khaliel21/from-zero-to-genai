{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "hf_token_api = os.environ['HF_TOKEN']\n",
    "pinecone_api_key = os.environ['PINECONE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "Model = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('Tell me a curious fact about {soccer_player}')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | Model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A curious fact about Cristiano Ronaldo is that he has a museum dedicated to himself, called the 'CR7 Museum', which is located in his hometown of Funchal, Madeira, Portugal. The museum showcases his achievements, awards, and memorabilia from throughout his career, including his numerous championship trophies and individual awards, such as his Ballon d'Or awards.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'soccer_player': 'Ronaldo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of .bind() to add arguments to a Runnable in LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop the execution when the specific stop word comming\n",
    "chain = prompt | Model.bind(stop = ['Ronaldo']) | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about Cristiano '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'soccer_player': 'Ronaldo'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinig LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "Model = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('Tell me a sentence about {politician}')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | Model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neville Chamberlain, the former Prime Minister of the United Kingdom, is often remembered for his policy of appeasement towards Nazi Germany, which ultimately failed to prevent the outbreak of World War II.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('Chamberlain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "historian_prompt = ChatPromptTemplate.from_template('Was {politician} positive for Humanity')\n",
    "\n",
    "composed_chain = {'politician' :  chain} | historian_prompt | Model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, Abraham Lincoln, the 16th President of the United States, is indeed widely regarded as one of the most influential leaders in American history, and his impact on humanity has been overwhelmingly positive. Here are some reasons why:\\n\\n1. **Abolition of Slavery**: Lincoln's strong stance against slavery and his commitment to ending the institution are well-documented. He issued the Emancipation Proclamation in 1863, which declared freedom for all slaves in the Confederate states. This move paved the way for the eventual abolition of slavery with the passage of the 13th Amendment to the Constitution in 1865.\\n2. **Unification of the Country**: Lincoln's leadership during the American Civil War (1861-1865) helped to preserve the Union and prevent the country from being torn apart by secession. His commitment to unity and his vision for a stronger, more unified America have had a lasting impact on the country's development.\\n3. **Advancement of Civil Rights**: Lincoln's commitment to equality and justice for all Americans, regardless of race or background, helped to lay the groundwork for the Civil Rights Movement of the 1950s and 1960s. His leadership and eloquence inspired future generations of civil rights leaders, including Martin Luther King Jr.\\n4. **Strengthening of Democracy**: Lincoln's dedication to democratic principles and his commitment to the rule of law helped to strengthen American democracy. His leadership during a time of great crisis and division helped to establish the United States as a beacon of freedom and democracy around the world.\\n5. **Inspiration to Future Generations**: Lincoln's life and legacy have inspired countless individuals, including world leaders, civil rights activists, and ordinary citizens. His humble beginnings, strong work ethic, and unwavering commitment to his principles have made him a role model for people of all ages and backgrounds.\\n\\nOverall, Abraham Lincoln's positive impact on humanity is undeniable. His leadership, vision, and commitment to justice and equality have left a lasting legacy that continues to inspire and shape American society and the world at large.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({'politician' : 'Lincoln'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le pays de François Mitterrand, la France, est situé sur le continent européen.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the country {politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what continent is the country {country} in? respond in {language}\")\n",
    "\n",
    "Model = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | Model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | Model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Mitterrand\", \"language\": \"French\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL Chain at Work in a Typical RAG app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough ,RunnableParallel\n",
    "from langchain import hub\n",
    "from langsmith import Client\n",
    "from bs4 import SoupStrainer\n",
    "import bs4\n",
    "\n",
    "# Définition du loader pour extraire uniquement certaines parties du HTML\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Chargement du contenu web\n",
    "docs = loader.load()\n",
    "\n",
    "# Découpage du texte en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=splits, embedding=model_embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n",
    "# prompt = hub.pull('rlm/rag-prompt')\n",
    "# prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | Model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complex task into smaller, simpler steps. This can be done through various methods, including using large language models (LLMs) with simple prompting, task-specific instructions, or human inputs. The goal of task decomposition is to transform big tasks into multiple manageable tasks, making it easier to plan and execute the task.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('What is Task Decomposition ?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
