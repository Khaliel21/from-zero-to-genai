{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Build a Simple Chatbot with Stored Memory using LangChain\n",
    "\n",
    "This script demonstrates how to build a simple LLM-based chatbot with memory using LangChain. The chatbot:\n",
    "- Can hold a conversation.\n",
    "- Remembers previous interactions by storing memory.\n",
    "- Saves memory into a JSON file for persistence.\n",
    "\n",
    "A chatbot app is a type of software designed to simulate conversations with human users. It uses AI to interpret user input and provide relevant responses. These bots can be applied in customer service, information delivery, or task assistance. In essence, itâ€™s like texting a smart assistant that can answer questions and help you out.\n",
    "\n",
    "Concepts Covered:\n",
    "- Chat Model vs LLM Model:\n",
    "    - Chat models operate on structured messages.\n",
    "    - LLM models operate on raw unstructured text.\n",
    "    - Enables the chat model to retain and utilize previous interactions for context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "hf_token_api = os.environ['HF_TOKEN']\n",
    "pinecone_api_key = os.environ['PINECONE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "chatbot = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages_to_the_bot = [\n",
    "    HumanMessage(content=\"My favorite color is green\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Green is a wonderful color, often associated with nature, growth, and harmony. It's a calming and balancing color that can evoke feelings of serenity and freshness. What do you like most about the color green? Is it the way it looks in nature, or do you have a favorite green object or item?\", response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 40, 'total_tokens': 104, 'completion_time': 0.232727273, 'prompt_time': 0.007710244, 'queue_time': 0.101011091, 'total_time': 0.240437517}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c4760ee73b', 'finish_reason': 'stop', 'logprobs': None}, id='run-ccb557bb-b4ae-4e12-bf34-861857e066a6-0', usage_metadata={'input_tokens': 40, 'output_tokens': 64, 'total_tokens': 104})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messages_to_the_bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### in final let's call LangSmith perform Traking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the Chatbot Remembers something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your favorite color. I'm a large language model, I don't have the ability to know personal preferences or details about individuals unless they're explicitly shared with me. If you'd like to share your favorite color, I'd be happy to chat with you about it!\", response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 41, 'total_tokens': 103, 'completion_time': 0.225454545, 'prompt_time': 0.003359917, 'queue_time': 0.100626885, 'total_time': 0.228814462}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_90c1d253ff', 'finish_reason': 'stop', 'logprobs': None}, id='run-01728ba7-4670-4cfa-a783-68d86137cb3a-0', usage_metadata={'input_tokens': 41, 'output_tokens': 62, 'total_tokens': 103})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [\n",
    "    HumanMessage(content='What is my favorite color ?')\n",
    "    ]\n",
    "chatbot.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because we gonna use the Memory Buffer\n",
    "    - we have tu use the lagecy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variable = [\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\AppData\\Local\\Temp\\ipykernel_18628\\3747834771.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Hello!',\n",
       " 'messages': [],\n",
       " 'text': \"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'My name is Dan',\n",
       " 'messages': [HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\")],\n",
       " 'text': \"Nice to meet you, Dan. It's great to have you here. Is there something on your mind that you'd like to talk about, or would you like some conversation ideas to get us started?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"My name is Dan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my name?',\n",
       " 'messages': [HumanMessage(content='Hello!'),\n",
       "  AIMessage(content=\"Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\"),\n",
       "  HumanMessage(content='My name is Dan'),\n",
       "  AIMessage(content=\"Nice to meet you, Dan. It's great to have you here. Is there something on your mind that you'd like to talk about, or would you like some conversation ideas to get us started?\")],\n",
       " 'text': 'Your name is Dan. You told me that a little earlier.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my name?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
