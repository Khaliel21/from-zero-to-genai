{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello \n"
     ]
    }
   ],
   "source": [
    "print(\"Hello \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Data Extraction App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "hf_token_api = os.environ['HF_TOKEN']\n",
    "pinecone_api_key = os.environ['PINECONE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name : Optional[str] = Field(\n",
    "        default= None, description=\"The First name of the person\"\n",
    "    )\n",
    "    lastname : Optional[str] = Field(\n",
    "        default= None, description=\"The lastname of the person\"\n",
    "    )\n",
    "    country : Optional[str] = Field(\n",
    "        default= None, description=\"The country of the person if know\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are an expert extraction algorithem.\"\n",
    "                \"Only extract relevant information from text.\"\n",
    "                \"If you do not know the value of attribute asked to extract,\"\n",
    "                \"return null for the attribute's value.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Structured Output with Chat Models\n",
    "\n",
    "- We need to use a model that supports function/tool calling.  \n",
    "- Please review the [documentation](https://platform.openai.com/docs/guides/function-calling) for a list of supported models.  \n",
    "- We will use `.with_structured_output()` to add the extraction instructions to our chat model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"James Carter is a data analyst living in Canada. He enjoys working with large datasets and creating insightful visualizations to help companies make better decisions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='James', lastname='Carter', country='Canada')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\" : comment})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name : Optional[str] = Field(\n",
    "        default= None, description=\"The First name of the person\"\n",
    "    )\n",
    "    lastname : Optional[str] = Field(\n",
    "        default= None, description=\"The lastname of the person\"\n",
    "    )\n",
    "    country : Optional[str] = Field(\n",
    "        default= None, description=\"The country of the person if know\"\n",
    "    )\n",
    "\n",
    "class Data(BaseModel):\n",
    "    people : List[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = \"\"\"\n",
    "Emily Zhang from Australia is a software engineer specializing in AI.\n",
    "Mohammed Al-Farsi, based in Oman, works as a cybersecurity consultant.\n",
    "Lucas Romero is a data scientist from Argentina with a passion for machine learning.\n",
    "Amina Diouf, originally from Senegal, is currently studying data engineering in France.\n",
    "Tomoko Saito lives in Japan and develops mobile apps for health tracking.\n",
    "\"\"\"\n",
    "\n",
    "response = chain.invoke({\"text\" : raw_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Emily', lastname='Zhang', country='Australia'), Person(name='Mohammed', lastname='Al-Farsi', country='Oman'), Person(name='Lucas', lastname='Romero', country='Argentina'), Person(name='Amina', lastname='Diouf', country='Senegal'), Person(name='Tomoko', lastname='Saito', country='Japan')])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
